{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mental-load-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cbYUxt1GX2jiTCdtLUfCV1tozRB0MpuA",
      "authorship_tag": "ABX9TyNOFaCAOfmzsTdH/YE8HkiI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avocadopelvis/mental-load/blob/main/mental_load_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "ypnKquskuawT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lK8dUdUnuACG"
      },
      "outputs": [],
      "source": [
        "# #LOAD DATA\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/MENTAL-LOAD-DATASET/final.csv\")\n",
        "# df = df.drop(df.columns[0], axis = 1)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use gpu if available \n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62DOKeozmzVw",
        "outputId": "415f2c96-9d57-482a-9d87-5b20e66d228e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/MENTAL-LOAD-DATASET/final.csv\")\n",
        "df = df.drop(df.columns[0], axis = 1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "VZEL-mN0RXF3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SignalDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "      # load dataset\n",
        "      # df = pd.read_csv(\"/content/drive/MyDrive/MENTAL-LOAD-DATASET/final.csv\")\n",
        "      # drop first column\n",
        "      # df = df.drop(df.columns[0], axis = 1)\n",
        "      # get x and convert to tensor\n",
        "      self.x = torch.tensor(df.iloc[:, 0:3840].values)\n",
        "      # get y and convert to tensor\n",
        "      self.y = torch.tensor(df[\"label\"].values)\n",
        "      # get number of samples\n",
        "      self.n_samples = df.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.n_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "OHEkU17GwBfg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SignalDataset(train)\n",
        "test_dataset = SignalDataset(test)\n",
        "# first = data[0]\n",
        "# X, y = first\n",
        "# print(X, y)"
      ],
      "metadata": {
        "id": "f0V1egMmZSNs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data for training with DataLoaders"
      ],
      "metadata": {
        "id": "8NkaFlPimPkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True) #,num_workers = 2\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "anGZpUcGkO8s"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataiter = iter(train_dataloader)\n",
        "# data = dataiter.next()\n",
        "# features, labels = data\n",
        "# print(features, labels)\n",
        "# len(features[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bLWkoEOfhT_",
        "outputId": "fc2dcbdb-f132-412f-d8e5-23e8fd75e28b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3840"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch import nn\n",
        "\n",
        "# class NeuralNetwork(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(NeuralNetwork, self).__init__()\n",
        "#         self.flatten = nn.Flatten()\n",
        "#         self.linear_relu_stack = nn.Sequential(\n",
        "#             nn.Linear(28*28, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(512, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(512, 10),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.flatten(x)\n",
        "#         logits = self.linear_relu_stack(x)\n",
        "#         return logits"
      ],
      "metadata": {
        "id": "BYBgGJVRmHvZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# hyperparameters\n",
        "input_size = 3840\n",
        "hidden_size = 100\n",
        "num_classes = 3\n",
        "num_epochs = 15\n",
        "batch_size = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes)"
      ],
      "metadata": {
        "id": "SRhXLS_7IiKa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = NeuralNetwork().to(device)\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "80Q9jKZPnQpJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS & OPTIMIZER\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "YZVawr1_oZ9o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_dataloader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs and labels\n",
        "    inputs, labels = data\n",
        "\n",
        "    # forward\n",
        "    outputs = model(inputs.float())\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 == 0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
        "\n",
        "# TEST\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for inputs, labels in test_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # value, index (We don't need value)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples == labels.shape[0]\n",
        "    n_correct == (predictions == labels).sum().item()\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "J2ukRUHoKRRZ",
        "outputId": "7d072574-a62c-49a7-dd65-e5eebd6ba87c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 15, step 100 / 189, loss = 0.0009\n",
            "epoch 2 / 15, step 100 / 189, loss = 0.0013\n",
            "epoch 3 / 15, step 100 / 189, loss = 0.0023\n",
            "epoch 4 / 15, step 100 / 189, loss = 0.0016\n",
            "epoch 5 / 15, step 100 / 189, loss = 0.0006\n",
            "epoch 6 / 15, step 100 / 189, loss = 0.0013\n",
            "epoch 7 / 15, step 100 / 189, loss = 0.0003\n",
            "epoch 8 / 15, step 100 / 189, loss = 0.0004\n",
            "epoch 9 / 15, step 100 / 189, loss = 0.0003\n",
            "epoch 10 / 15, step 100 / 189, loss = 0.0004\n",
            "epoch 11 / 15, step 100 / 189, loss = 0.0004\n",
            "epoch 12 / 15, step 100 / 189, loss = 0.0003\n",
            "epoch 13 / 15, step 100 / 189, loss = 0.0002\n",
            "epoch 14 / 15, step 100 / 189, loss = 0.0002\n",
            "epoch 15 / 15, step 100 / 189, loss = 0.0001\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a8f31b1b9e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# value, index (We don't need value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-58403c25e3a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for inputs, labels in test_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # value, index (We don't need value)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples == labels.shape[0]\n",
        "    n_correct == (predictions == labels).sum().item()\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "id": "ITY958BaSv5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "#     running_loss = 0.0\n",
        "#     for i, data in enumerate(dataloader, 0):\n",
        "#         # get the inputs and labels\n",
        "#         inputs, labels = data\n",
        "\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(inputs)\n",
        "          # calculate loss\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # print statistics\n",
        "#         running_loss += loss.item()\n",
        "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "#             running_loss = 0.0\n",
        "\n",
        "# print('Finished Training')"
      ],
      "metadata": {
        "id": "DJuaozZLof_f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class SignalDataset(Dataset):\n",
        "#     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "#         self.labels = y\n",
        "#         self.samples = X\n",
        "#         self.transform = transform\n",
        "#         self.target_transform = target_transform\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.labels)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         path = os.path.join(self.samples.iloc[idx, 0], self.labels.iloc[idx, 0])\n",
        "#         sample = self.samples.iloc[idx, 0]  #FIGURE OUT HOW TO READ SAMPLE\n",
        "#         label = self.labels.iloc[idx, 1]\n",
        "#         if self.transform:\n",
        "#             sample = self.transform(sample)\n",
        "#         if self.target_transform:\n",
        "#             label = self.target_transform(label)\n",
        "#         return sample, label"
      ],
      "metadata": {
        "id": "nLk0iE3GowRZ"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}