{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mental-load-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cbYUxt1GX2jiTCdtLUfCV1tozRB0MpuA",
      "authorship_tag": "ABX9TyOgqRJZXai0US6rUJ6XnmkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avocadopelvis/mental-load/blob/main/mental_load_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "ypnKquskuawT"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use gpu if available \n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62DOKeozmzVw",
        "outputId": "9fa7dc67-b42c-441f-dd99-8bce9b1c116c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/MENTAL-LOAD-DATASET/final.csv\")\n",
        "# drop first column\n",
        "df = df.drop(df.columns[0], axis = 1)\n",
        "\n",
        "# split data into training & testing data\n",
        "train, test = train_test_split(df, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "VZEL-mN0RXF3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SignalDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "      # get x and convert to tensor\n",
        "      self.x = torch.tensor(df.iloc[:, 0:3840].values)\n",
        "      # get y and convert to tensor\n",
        "      self.y = torch.tensor(df[\"label\"].values)\n",
        "      # get number of samples\n",
        "      self.n_samples = df.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.n_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "OHEkU17GwBfg"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SignalDataset(train)\n",
        "test_dataset = SignalDataset(test)"
      ],
      "metadata": {
        "id": "f0V1egMmZSNs"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 3840\n",
        "hidden_size = 2500 \n",
        "num_classes = 3\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 10\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "JDZVRtg0pJO5"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) #,num_workers = 2\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "anGZpUcGkO8s"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FULLY CONNECTED NEURAL NETWORK\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "    # self.relu = nn.ReLU()\n",
        "    # self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    # out = self.relu(out)\n",
        "    # out = self.l3(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "SRhXLS_7IiKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332f719c-d060-4598-ea85-5fe704ee8ada"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (l1): Linear(in_features=3840, out_features=2500, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (l2): Linear(in_features=2500, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS & OPTIMIZER\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9)"
      ],
      "metadata": {
        "id": "YZVawr1_oZ9o"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING LOOP\n",
        "n_total_steps = len(train_dataloader)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs and labels\n",
        "    inputs, labels = data\n",
        "\n",
        "    # forward\n",
        "    outputs = model(inputs.float())\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 == 0:\n",
        "      print(f'epoch {epoch+1} / {epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q574jeks_GT",
        "outputId": "b48d8494-6aa2-4fc7-dfba-e527e2e32709"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 20, step 100 / 168, loss = 1.2215\n",
            "epoch 2 / 20, step 100 / 168, loss = 1.2909\n",
            "epoch 3 / 20, step 100 / 168, loss = 0.3311\n",
            "epoch 4 / 20, step 100 / 168, loss = 0.5267\n",
            "epoch 5 / 20, step 100 / 168, loss = 0.1789\n",
            "epoch 6 / 20, step 100 / 168, loss = 0.2306\n",
            "epoch 7 / 20, step 100 / 168, loss = 0.0394\n",
            "epoch 8 / 20, step 100 / 168, loss = 0.0108\n",
            "epoch 9 / 20, step 100 / 168, loss = 0.5236\n",
            "epoch 10 / 20, step 100 / 168, loss = 0.0051\n",
            "epoch 11 / 20, step 100 / 168, loss = 0.0006\n",
            "epoch 12 / 20, step 100 / 168, loss = 0.0153\n",
            "epoch 13 / 20, step 100 / 168, loss = 1.2819\n",
            "epoch 14 / 20, step 100 / 168, loss = 0.0117\n",
            "epoch 15 / 20, step 100 / 168, loss = 1.5076\n",
            "epoch 16 / 20, step 100 / 168, loss = 0.0481\n",
            "epoch 17 / 20, step 100 / 168, loss = 0.4875\n",
            "epoch 18 / 20, step 100 / 168, loss = 0.0000\n",
            "epoch 19 / 20, step 100 / 168, loss = 0.2261\n",
            "epoch 20 / 20, step 100 / 168, loss = 0.0090\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for inputs, labels in test_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs.float())\n",
        "\n",
        "    # value, index (We don't need value)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "id": "ITY958BaSv5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b551a6e3-7349-4f27-cc57-525fdbce34fd"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 39.523809523809526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "#     size = len(dataloader.dataset)\n",
        "#     for batch, (X, y) in enumerate(dataloader):\n",
        "#         # Compute prediction and loss\n",
        "#         pred = model(X.float())\n",
        "#         loss = loss_fn(pred, y)\n",
        "\n",
        "#         # Backpropagation\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         if batch % 100 == 0:\n",
        "#             loss, current = loss.item(), batch * len(X)\n",
        "#             print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "# def test_loop(dataloader, model, loss_fn):\n",
        "#     size = len(dataloader.dataset)\n",
        "#     num_batches = len(dataloader)\n",
        "#     test_loss, correct = 0, 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for X, y in dataloader:\n",
        "#             pred = model(X.float())\n",
        "#             test_loss += loss_fn(pred, y).item()\n",
        "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "#     test_loss /= num_batches\n",
        "#     correct /= size\n",
        "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "syp2vDtaxu1Z"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for t in range(num_epochs):\n",
        "#     print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "#     train_loop(train_dataloader, model, criterion, optimizer)\n",
        "#     test_loop(test_dataloader, model, criterion)\n",
        "# print(\"Done!\")"
      ],
      "metadata": {
        "id": "OJLqt2vmx2XQ"
      },
      "execution_count": 106,
      "outputs": []
    }
  ]
}